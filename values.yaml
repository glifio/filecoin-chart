# Default values file for the chart
# This is a YAML-formatted file
# Declare variables to be passed into your templates

replicaCount: 1

# Uncomment the client you are going to install. By default it is Lotus
client: "lotus"
image:
  repo: glif/lotus
  pullPolicy: IfNotPresent
  tag: v1.12.0-rc1-calibnet
# client: "lily"
# image:
#   repo: filecoin/lily
#   pullPolicy: IfNotPresent
#   tag: "calibnet-latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

# Due to unstable update process for k8s clusters that use spot instances in some cases we run several releases
# with several statefulsets covered by a single service. The service selects pods by releaseGroup label.
# In all other cases the value should be unique
releaseGroup: fil-group

# If client is lily comment this section
securityContext:
  runAsNonRoot: true
  runAsUser: 2000
  runAsGroup: 2000
  fsGroup: 2000

nodeSelector:
  role: worker

affinity: {}
  # podAntiAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     - labelSelector:
  #         matchExpressions:
  #           - key: app
  #             operator: In
  #             values:
  #               - lotus-node-app
  #       topologyKey: "kubernetes.io/hostname"

tolerations: []

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # The name of the service account to use. Will be prefixed with release name
  name: acc

# Filecoin daemon service settings
daemon:
  # Set enabled to true to run lily or lotus in daemon mode with its own data store
  enabled: true
  args: []
  env: []
  importSnapshot:
    enabled: false
    url: SOME_URL
    cid:
    ipfsGw:

  # daemon resources
  # Note: Running lily on mainnet requires SIGNIFICANT resources (>250Gb RAM)
  # in order to operate comfortably. Test networks may be preferred if resources
  # are limited.
  resources:
    requests:
      cpu: 500m
      memory: 3Gi
    limits:
      cpu: 1900m
      memory: 5Gi
  secretVolume:
    enabled: true
    persistNodeID: false

  # daemon storage is a list of storage configurations that will be added to
  # the lily config and used when starting jobs
  storage:
    postgresql: []
    #- name: db
      #secretName: postgresql-secret
      #secretKey: url
      #schema: lily
      #applicationName: lily
      #poolSize: 20
      #allowUpsert: false
    file: []
    #- name: csv
      #format: CSV
      #path: /tmp

  # jobs is a list of jobs to start on the lily daemon
  jobs: []
  #- command: watch
    #name: ""
    #jobId: ""
    #args:
    #- --confidence=10
    #- --tasks=blocks,messages,chaineconomics
    #- --storage=

  # genesisUnix should be the unix time of the genesis epoch
  # and is used to calculate relative to/from windows for
  # each gapfill job. Default genesis is set for mainnet.
  genesisUnix: "1598306400"

  # gapfill describes a list of gapfill jobs to start on the daemon once
  # every 24 hours
  gapfill:
    enabled: false
    # storage is the storage.postgresql[].name on which execute the gapfill job
    storage: "db"
    # taskSets is a list of comma-separated strings indicating the tasks for each
    # gapfill job. Each item will start as an indpendent job with the tasks listed.
    # Default is defined in `lily gap <find|fill> --help`
    taskSets:
    # examples
    #- actorstatesmultisig,actorstatespower,actorstatesraw,actorstatesreward,actorstatesverifreg,blocks,chaineconomics,consensus,implicitmessage,messages,msapprovals
    #- actorstatesinit,actorstatesmarket
    #- messages
    cron: "0 0 * * *"

  # daemon pubsub-specific settings
  pubsub:
    # ipwhitelist maps to Pubsub.IPColocationWhitelist in daemon's config.toml
    ipwhitelist: []

  # How long to wait for the daemon to start before failing
  apiWaitTimeout: 60s

# IPFS service settings
ipfs:
  enabled: false
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 3000m
      memory: 3Gi
  dns:

## Cashe service settings
cache:
  enabled: false
  image: protofire/filecoin-rpc-proxy:0.0.3
  replicas: 2
  nodeSelector:
    nodeLabel:
      role: worker

# Storage persistence settings
persistence:
  # If persistence is set to false no persistent volumes will be created
  enabled: false
  hostPath: /nvme/disk
  autoResizer:
    enabled: true
    increaseThreshold: 90 # in %
    increaseStep: 10 # in %
    cron: "0 0 * * *"
  snapshots:
    # If uploadToIpfs is set to true the internal Lotus snapshot will be created 
    # and uploaded to the IPFS system. Note that IPFS must be enabled in that case
    uploadToIpfs:
      enabled: false
      export: hot
      # shedPeriod: 6h
      shareToGist:
        enabled: false
        cron: "0 0 * * *"
        address: https://gist.github.com/openworklabbot/d03393d1f6e70e089e9e8d18922474f6
        authorEmail: email
        authorName: Protofire Bot
    # If snapshots are enabled - the PV will be deployed with ebs-sc class unless custom class is specified
    enabled: true
    # If automation is enabled - several CronJobs will be created to create snapshots and/or delete old snapshots automatically.
    automation:
      deletion:
        cron: "0 1 * * *"
        enabled: true
        retention:
          count: 2
      creation:
        cron: "0 0 * * *"
        enabled: true
    # If restore is enabled the snapshot name must be specified. Charts will attempt to find the existing snapshot with this name and create a PV from that snapshot.
    restore:
      enabled: false
      name: 
  # For each of the deployed services one can specify the disk size, custom disk type and access mode.
  daemon:
    size: "5500Gi"
    accessModes:
      - ReadWriteOnce
    storageClass: "ebs-sc"
  ipfs:
    size: "350Gi"
    accessModes:
      - ReadWriteOnce
    storageClass: "ebs-sc" 
    
# Service monitoring settings
prometheusOperatorServiceMonitor: false
prometheusPort: 9991

# Service tracing settings
jaeger:
  enabled: false
  host: ""        # default: node.status.hostIP
  serviceName: "" # default: include sentinel-lily.instanceName
  port: "6831"
  sampler:
    type: "probabilistic"
    param: "0.0001"

# Debug feature config
debug:
  enabled: false
  resources:
    requests:
      cpu: "8000m"
      memory: "16Gi"
    limits:
      cpu: "8000m"
      memory: "16Gi"


# Some additional environment variables for Filecoin daemon
# ???????
lotusMaxHeap: false 
# ???????
infraClearRestart: false
# ???????
infraSync: true

logLevel: info
logLevelNamed: "vm:error,badgerbs:error"
logFormat: json

healthcheck:
  enabled: true
  readinessProbe: true
  network: calibration
  allowedDelay:

# Ingress settings
ingress:
  enabled: true
  host: dev.node.glif.io
  annotations:
    nginx.ingress.kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-headers: "Authorization,Accept,Origin,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Length,Content-Range,Range"
    nginx.ingress.kubernetes.io/enable-rewrite-log: "true"
    # nginx.ingress.kubernetes.io/server-alias: "_"
    nginx.ingress.kubernetes.io/enable-modsecurity: "true"
    nginx.ingress.kubernetes.io/modsecurity-snippet: |
      SecRuleEngine On
      SecDebugLog /tmp/modsec_debug.log
  daemon:
    enabled: true
    gateway: false
    # Uncomment following annotations to change access mode from JWT-based to Firewall-based. Also replace <JWT> with admin JWT token of the node and 1.2.3.4/32 to your IP address.
    annotations: {}
    # nginx.ingress.kubernetes.io/whitelist-source-range: 1.2.3.4/32
    # nginx.ingress.kubernetes.io/configuration-snippet: |
    #       proxy_set_header Authorization "Bearer <JWT>";
  ipfs:
    enabled: false
    annotations: {}

# Additional labels for helpers
labels: {}
release: 
  # nameOverride is used to name the instance in external systems. If empty,
  # then the network, environment, and release name values are used with the
  # chart name to generate a name.
  #nameOverride:
  network: mainnet
  environment: dev
